# Docker + Nginx å®¹å™¨åŒ–éƒ¨ç½²å®Œå…¨æŒ‡å—

Docker ä¸ Nginx çš„ç»“åˆæ˜¯ç°ä»£ Web åº”ç”¨éƒ¨ç½²çš„é»„é‡‘ç»„åˆã€‚Docker æä¾›äº†ä¸€è‡´çš„è¿è¡Œç¯å¢ƒï¼ŒNginx ä½œä¸ºé«˜æ€§èƒ½çš„ Web æœåŠ¡å™¨å’Œåå‘ä»£ç†ï¼Œä¸¤è€…ç»“åˆèƒ½å¤Ÿå®ç°é«˜æ•ˆã€å¯æ‰©å±•çš„åº”ç”¨éƒ¨ç½²æ¶æ„ã€‚

## ğŸ³ Docker åŸºç¡€æ¦‚å¿µ

### Docker æ ¸å¿ƒæ¦‚å¿µ

```mermaid
graph TB
    A[Docker æ¶æ„] --> B[Docker Client]
    A --> C[Docker Daemon]
    A --> D[Docker Registry]

    B --> E[docker build]
    B --> F[docker run]
    B --> G[docker pull]

    C --> H[å®¹å™¨ç®¡ç†]
    C --> I[é•œåƒç®¡ç†]
    C --> J[ç½‘ç»œç®¡ç†]

    D --> K[Docker Hub]
    D --> L[ç§æœ‰ä»“åº“]
    D --> M[Harbor]
```

### Docker æ ¸å¿ƒç»„ä»¶

- **é•œåƒ (Image)**: åªè¯»çš„æ¨¡æ¿ï¼ŒåŒ…å«è¿è¡Œåº”ç”¨æ‰€éœ€çš„æ‰€æœ‰å†…å®¹
- **å®¹å™¨ (Container)**: é•œåƒçš„è¿è¡Œå®ä¾‹ï¼Œæä¾›éš”ç¦»çš„è¿è¡Œç¯å¢ƒ
- **Dockerfile**: ç”¨äºæ„å»ºé•œåƒçš„æ–‡æœ¬æ–‡ä»¶ï¼ŒåŒ…å«ä¸€ç³»åˆ—æŒ‡ä»¤
- **ä»“åº“ (Registry)**: å­˜å‚¨å’Œåˆ†å‘é•œåƒçš„æœåŠ¡

## ğŸ—ï¸ Dockerfile æœ€ä½³å®è·µ

### 1. å‰ç«¯åº”ç”¨ Dockerfile

```dockerfile
# å¤šé˜¶æ®µæ„å»º - å‰ç«¯ React/Vue åº”ç”¨
FROM node:18-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ package æ–‡ä»¶
COPY package*.json ./

# å®‰è£…ä¾èµ–
RUN npm ci --only=production

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN npm run build

# ç”Ÿäº§é˜¶æ®µ - ä½¿ç”¨ Nginx æœåŠ¡é™æ€æ–‡ä»¶
FROM nginx:alpine

# å¤åˆ¶è‡ªå®šä¹‰ nginx é…ç½®
COPY nginx.conf /etc/nginx/nginx.conf

# å¤åˆ¶æ„å»ºäº§ç‰©åˆ° nginx ç›®å½•
COPY --from=builder /app/dist /usr/share/nginx/html

# å¤åˆ¶ SSL è¯ä¹¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
# COPY ssl/ /etc/nginx/ssl/

# æš´éœ²ç«¯å£
EXPOSE 80 443

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost/health || exit 1

# å¯åŠ¨ nginx
CMD ["nginx", "-g", "daemon off;"]
```

### 2. Node.js åç«¯åº”ç”¨ Dockerfile

```dockerfile
# Node.js åç«¯åº”ç”¨
FROM node:18-alpine AS base

# å®‰è£… dumb-init ç”¨äºä¿¡å·å¤„ç†
RUN apk add --no-cache dumb-init

# åˆ›å»ºé root ç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ package æ–‡ä»¶
COPY package*.json ./

# ä¾èµ–å®‰è£…é˜¶æ®µ
FROM base AS deps
RUN npm ci --only=production && npm cache clean --force

# å¼€å‘ä¾èµ–å®‰è£…é˜¶æ®µ
FROM base AS deps-dev
RUN npm ci

# æ„å»ºé˜¶æ®µ
FROM deps-dev AS builder
COPY . .
RUN npm run build

# ç”Ÿäº§é˜¶æ®µ
FROM base AS runner

# å¤åˆ¶ç”Ÿäº§ä¾èµ–
COPY --from=deps --chown=nextjs:nodejs /app/node_modules ./node_modules

# å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder --chown=nextjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nextjs:nodejs /app/package.json ./package.json

# åˆ‡æ¢åˆ°é root ç”¨æˆ·
USER nextjs

# æš´éœ²ç«¯å£
EXPOSE 3000

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV NODE_ENV=production
ENV PORT=3000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js

# å¯åŠ¨åº”ç”¨
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/index.js"]
```

### 3. å…¨æ ˆåº”ç”¨ Docker Compose

```yaml
# docker-compose.yml
version: "3.8"

services:
  # å‰ç«¯æœåŠ¡
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: production
    container_name: app-frontend
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/logs:/var/log/nginx
    depends_on:
      - backend
    networks:
      - app-network
    environment:
      - NODE_ENV=production
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`example.com`)"
      - "traefik.http.routers.frontend.tls=true"

  # åç«¯æœåŠ¡
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: app-backend
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET=${JWT_SECRET}
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    depends_on:
      - database
      - redis
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # æ•°æ®åº“æœåŠ¡
  database:
    image: postgres:15-alpine
    container_name: app-database
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${DB_NAME}
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis ç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: app-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    ports:
      - "6379:6379"
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # ç›‘æ§æœåŠ¡
  monitoring:
    image: prom/prometheus:latest
    container_name: app-monitoring
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - app-network
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"

# ç½‘ç»œé…ç½®
networks:
  app-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# æ•°æ®å·
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
```

## ğŸŒ Nginx é…ç½®è¯¦è§£

### 1. åŸºç¡€ Nginx é…ç½®

```nginx
# nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

# ä¼˜åŒ–é…ç½®
worker_rlimit_nofile 65535;

events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
}

http {
    # åŸºç¡€é…ç½®
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    '$request_time $upstream_response_time';

    access_log /var/log/nginx/access.log main;

    # æ€§èƒ½ä¼˜åŒ–
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    keepalive_requests 100;

    # Gzip å‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # Brotli å‹ç¼©ï¼ˆå¦‚æœæ”¯æŒï¼‰
    # brotli on;
    # brotli_comp_level 6;
    # brotli_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

    # å®‰å…¨å¤´
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header Referrer-Policy "no-referrer-when-downgrade" always;
    add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'" always;

    # é™åˆ¶è¯·æ±‚å¤§å°
    client_max_body_size 100M;
    client_body_buffer_size 128k;
    client_header_buffer_size 3m;
    large_client_header_buffers 4 256k;

    # è¶…æ—¶è®¾ç½®
    client_body_timeout 10;
    client_header_timeout 10;
    send_timeout 10;

    # ç¼“å­˜è®¾ç½®
    open_file_cache max=100000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;

    # ä¸Šæ¸¸æœåŠ¡å™¨é…ç½®
    upstream backend {
        least_conn;
        server backend:3000 max_fails=3 fail_timeout=30s;
        # server backend2:3000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    # é™æµé…ç½®
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;

    # ä¸»æœåŠ¡å™¨é…ç½®
    server {
        listen 80;
        server_name example.com www.example.com;

        # HTTP é‡å®šå‘åˆ° HTTPS
        return 301 https://$server_name$request_uri;
    }

    # HTTPS æœåŠ¡å™¨é…ç½®
    server {
        listen 443 ssl http2;
        server_name example.com www.example.com;

        # SSL é…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_session_cache shared:SSL:1m;
        ssl_session_timeout 5m;
        ssl_ciphers HIGH:!aNULL:!MD5;
        ssl_prefer_server_ciphers on;
        ssl_protocols TLSv1.2 TLSv1.3;

        # HSTS
        add_header Strict-Transport-Security "max-age=63072000" always;

        # é™æ€æ–‡ä»¶æ ¹ç›®å½•
        root /usr/share/nginx/html;
        index index.html index.htm;

        # é™æ€èµ„æºç¼“å­˜
        location ~* \.(jpg|jpeg|png|gif|ico|css|js|woff|woff2|ttf|eot|svg)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            add_header Vary Accept-Encoding;
            access_log off;
        }

        # API ä»£ç†
        location /api/ {
            limit_req zone=api burst=20 nodelay;

            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;

            # è¶…æ—¶è®¾ç½®
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;

            # é”™è¯¯å¤„ç†
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
        }

        # WebSocket æ”¯æŒ
        location /ws/ {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_read_timeout 86400;
        }

        # ç™»å½•é™æµ
        location /api/auth/login {
            limit_req zone=login burst=5 nodelay;
            proxy_pass http://backend;
            include /etc/nginx/proxy_params;
        }

        # å¥åº·æ£€æŸ¥
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # SPA è·¯ç”±æ”¯æŒ
        location / {
            try_files $uri $uri/ /index.html;

            # ç¼“å­˜æ§åˆ¶
            location = /index.html {
                add_header Cache-Control "no-cache, no-store, must-revalidate";
                add_header Pragma "no-cache";
                add_header Expires "0";
            }
        }

        # å®‰å…¨é…ç½®
        location ~ /\. {
            deny all;
            access_log off;
            log_not_found off;
        }

        # ç¦æ­¢è®¿é—®æ•æ„Ÿæ–‡ä»¶
        location ~* \.(env|log|ini)$ {
            deny all;
            access_log off;
            log_not_found off;
        }

        # é”™è¯¯é¡µé¢
        error_page 404 /404.html;
        error_page 500 502 503 504 /50x.html;

        location = /50x.html {
            root /usr/share/nginx/html;
        }
    }

    # è´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»
    server {
        listen 8080;
        server_name admin.example.com;

        location / {
            proxy_pass http://backend;

            # å¥åº·æ£€æŸ¥
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503;
            proxy_next_upstream_tries 3;
            proxy_next_upstream_timeout 10s;

            include /etc/nginx/proxy_params;
        }
    }
}
```

### 2. é«˜çº§ Nginx é…ç½®

```nginx
# advanced-nginx.conf - é«˜çº§é…ç½®ç¤ºä¾‹

# å…¨å±€é…ç½®
user nginx;
worker_processes auto;
worker_cpu_affinity auto;
worker_rlimit_nofile 100000;

error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
    accept_mutex off;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼
    log_format detailed '$remote_addr - $remote_user [$time_local] '
                       '"$request" $status $bytes_sent '
                       '"$http_referer" "$http_user_agent" '
                       '"$http_x_forwarded_for" $request_id '
                       'rt=$request_time uct="$upstream_connect_time" '
                       'uht="$upstream_header_time" urt="$upstream_response_time"';

    # æ€§èƒ½ä¼˜åŒ–
    sendfile on;
    sendfile_max_chunk 1m;
    tcp_nopush on;
    tcp_nodelay on;

    # è¿æ¥ä¿æŒ
    keepalive_timeout 75s;
    keepalive_requests 1000;

    # ç¼“å†²åŒºä¼˜åŒ–
    client_body_buffer_size 256k;
    client_header_buffer_size 64k;
    large_client_header_buffers 4 64k;
    output_buffers 2 32k;
    postpone_output 1460;

    # å‹ç¼©ä¼˜åŒ–
    gzip on;
    gzip_vary on;
    gzip_min_length 1000;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        text/x-component
        application/json
        application/javascript
        application/x-javascript
        application/xml
        application/xml+rss
        application/xhtml+xml
        application/x-font-ttf
        application/vnd.ms-fontobject
        font/opentype
        image/svg+xml
        image/x-icon;

    # ç¼“å­˜é…ç½®
    proxy_cache_path /var/cache/nginx/proxy levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;
    proxy_cache_key "$scheme$request_method$host$request_uri";

    # é™æµé…ç½®
    limit_req_zone $binary_remote_addr zone=global:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=api:10m rate=5r/s;
    limit_req_zone $binary_remote_addr zone=auth:10m rate=1r/s;
    limit_conn_zone $binary_remote_addr zone=conn_limit_per_ip:10m;

    # ä¸Šæ¸¸æœåŠ¡å™¨ç»„
    upstream app_backend {
        least_conn;
        server backend1:3000 weight=3 max_fails=3 fail_timeout=30s;
        server backend2:3000 weight=2 max_fails=3 fail_timeout=30s;
        server backend3:3000 weight=1 max_fails=3 fail_timeout=30s backup;

        keepalive 32;
        keepalive_requests 100;
        keepalive_timeout 60s;
    }

    # å¾®æœåŠ¡ä¸Šæ¸¸
    upstream user_service {
        server user-service:3001;
        keepalive 16;
    }

    upstream order_service {
        server order-service:3002;
        keepalive 16;
    }

    # åœ°ç†ä½ç½®é…ç½®
    geo $limit {
        default 1;
        10.0.0.0/8 0;
        192.168.0.0/16 0;
        172.16.0.0/12 0;
    }

    map $limit $limit_key {
        0 "";
        1 $binary_remote_addr;
    }

    # ä¸»æœåŠ¡å™¨é…ç½®
    server {
        listen 443 ssl http2;
        server_name api.example.com;

        # SSL é…ç½®
        ssl_certificate /etc/nginx/ssl/api.example.com.crt;
        ssl_certificate_key /etc/nginx/ssl/api.example.com.key;
        ssl_session_cache shared:SSL:50m;
        ssl_session_timeout 1d;
        ssl_session_tickets off;

        # ç°ä»£ SSL é…ç½®
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;

        # OCSP Stapling
        ssl_stapling on;
        ssl_stapling_verify on;

        # å®‰å…¨å¤´
        add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload";
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Referrer-Policy "strict-origin-when-cross-origin";

        # å…¨å±€é™æµ
        limit_req zone=global burst=50 nodelay;
        limit_conn conn_limit_per_ip 20;

        # API ç½‘å…³é…ç½®
        location /api/v1/users {
            limit_req zone=api burst=10 nodelay;

            proxy_pass http://user_service;
            proxy_cache my_cache;
            proxy_cache_valid 200 302 10m;
            proxy_cache_valid 404 1m;
            proxy_cache_bypass $arg_nocache;

            include /etc/nginx/proxy_headers.conf;
        }

        location /api/v1/orders {
            limit_req zone=api burst=10 nodelay;

            proxy_pass http://order_service;
            proxy_cache my_cache;
            proxy_cache_valid 200 5m;

            include /etc/nginx/proxy_headers.conf;
        }

        # è®¤è¯æœåŠ¡
        location /api/v1/auth {
            limit_req zone=auth burst=5 nodelay;

            proxy_pass http://app_backend;
            proxy_no_cache 1;
            proxy_cache_bypass 1;

            include /etc/nginx/proxy_headers.conf;
        }

        # æ–‡ä»¶ä¸Šä¼ 
        location /api/v1/upload {
            client_max_body_size 50M;
            proxy_request_buffering off;
            proxy_pass http://app_backend;

            include /etc/nginx/proxy_headers.conf;
        }

        # WebSocket ä»£ç†
        location /ws {
            proxy_pass http://app_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_read_timeout 86400;
        }

        # å¥åº·æ£€æŸ¥
        location /health {
            access_log off;
            return 200 '{"status":"ok","timestamp":"$time_iso8601"}';
            add_header Content-Type application/json;
        }

        # ç›‘æ§ç«¯ç‚¹
        location /nginx_status {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            allow 10.0.0.0/8;
            deny all;
        }
    }

    # CDN æœåŠ¡å™¨
    server {
        listen 443 ssl http2;
        server_name cdn.example.com;

        ssl_certificate /etc/nginx/ssl/cdn.example.com.crt;
        ssl_certificate_key /etc/nginx/ssl/cdn.example.com.key;

        root /var/www/cdn;

        # é™æ€èµ„æºä¼˜åŒ–
        location ~* \.(jpg|jpeg|png|gif|ico|webp|avif)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            add_header Vary Accept-Encoding;

            # å›¾ç‰‡ä¼˜åŒ–
            image_filter_buffer 20M;
            image_filter_jpeg_quality 85;

            access_log off;
        }

        location ~* \.(css|js|woff|woff2|ttf|eot|svg)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            gzip_static on;
            access_log off;
        }

        # é˜²ç›—é“¾
        location ~* \.(jpg|jpeg|png|gif)$ {
            valid_referers none blocked server_names
                           *.example.com example.com;
            if ($invalid_referer) {
                return 403;
            }
        }
    }
}
```

### 3. Nginx ä»£ç†å‚æ•°é…ç½®

```nginx
# proxy_headers.conf - ä»£ç†å¤´æ–‡ä»¶
proxy_http_version 1.1;
proxy_cache_bypass $http_upgrade;

# åŸºç¡€ä»£ç†å¤´
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection $connection_upgrade;
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header X-Forwarded-Proto $scheme;
proxy_set_header X-Forwarded-Host $host;
proxy_set_header X-Forwarded-Port $server_port;

# è¯·æ±‚ ID ä¼ é€’
proxy_set_header X-Request-ID $request_id;

# è¶…æ—¶è®¾ç½®
proxy_connect_timeout 60s;
proxy_send_timeout 60s;
proxy_read_timeout 60s;

# ç¼“å†²è®¾ç½®
proxy_buffering on;
proxy_buffer_size 128k;
proxy_buffers 4 256k;
proxy_busy_buffers_size 256k;

# é”™è¯¯å¤„ç†
proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
proxy_next_upstream_tries 3;
proxy_next_upstream_timeout 10s;
```

## ğŸš€ Docker éƒ¨ç½²ç­–ç•¥

### 1. è“ç»¿éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# blue-green-deploy.sh - è“ç»¿éƒ¨ç½²è„šæœ¬

set -e

# é…ç½®å˜é‡
IMAGE_NAME="myapp"
VERSION=${1:-latest}
BLUE_CONTAINER="myapp-blue"
GREEN_CONTAINER="myapp-green"
NGINX_CONFIG_DIR="/etc/nginx/conf.d"

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

error() {
    echo -e "${RED}[ERROR] $1${NC}"
    exit 1
}

warn() {
    echo -e "${YELLOW}[WARN] $1${NC}"
}

# æ£€æŸ¥å½“å‰æ´»è·ƒå®¹å™¨
get_active_container() {
    if docker ps | grep -q $BLUE_CONTAINER; then
        echo "blue"
    elif docker ps | grep -q $GREEN_CONTAINER; then
        echo "green"
    else
        echo "none"
    fi
}

# è·å–éæ´»è·ƒå®¹å™¨
get_inactive_container() {
    local active=$(get_active_container)
    if [ "$active" = "blue" ]; then
        echo "green"
    else
        echo "blue"
    fi
}

# å¥åº·æ£€æŸ¥
health_check() {
    local container=$1
    local port=$2
    local max_attempts=30
    local attempt=1

    log "å¼€å§‹å¥åº·æ£€æŸ¥: $container"

    while [ $attempt -le $max_attempts ]; do
        if curl -f -s "http://localhost:$port/health" > /dev/null; then
            log "å¥åº·æ£€æŸ¥é€šè¿‡: $container"
            return 0
        fi

        log "å¥åº·æ£€æŸ¥å¤±è´¥ ($attempt/$max_attempts), ç­‰å¾… 10 ç§’..."
        sleep 10
        attempt=$((attempt + 1))
    done

    error "å¥åº·æ£€æŸ¥å¤±è´¥: $container"
}

# æ›´æ–° Nginx é…ç½®
update_nginx_config() {
    local target_container=$1
    local target_port

    if [ "$target_container" = "blue" ]; then
        target_port=3001
    else
        target_port=3002
    fi

    log "æ›´æ–° Nginx é…ç½®æŒ‡å‘: $target_container (ç«¯å£: $target_port)"

    cat > $NGINX_CONFIG_DIR/upstream.conf << EOF
upstream backend {
    server localhost:$target_port;
}
EOF

    # é‡æ–°åŠ è½½ Nginx é…ç½®
    if command -v nginx > /dev/null; then
        nginx -t && nginx -s reload
    else
        docker exec nginx nginx -t && docker exec nginx nginx -s reload
    fi

    log "Nginx é…ç½®æ›´æ–°å®Œæˆ"
}

# éƒ¨ç½²æ–°ç‰ˆæœ¬
deploy_new_version() {
    local target_env=$(get_inactive_container)
    local target_container
    local target_port

    if [ "$target_env" = "blue" ]; then
        target_container=$BLUE_CONTAINER
        target_port=3001
    else
        target_container=$GREEN_CONTAINER
        target_port=3002
    fi

    log "å¼€å§‹éƒ¨ç½²åˆ° $target_env ç¯å¢ƒ"

    # åœæ­¢å¹¶åˆ é™¤ç°æœ‰å®¹å™¨
    if docker ps -a | grep -q $target_container; then
        log "åœæ­¢ç°æœ‰å®¹å™¨: $target_container"
        docker stop $target_container || true
        docker rm $target_container || true
    fi

    # å¯åŠ¨æ–°å®¹å™¨
    log "å¯åŠ¨æ–°å®¹å™¨: $target_container"
    docker run -d \
        --name $target_container \
        --restart unless-stopped \
        -p $target_port:3000 \
        -e NODE_ENV=production \
        -e PORT=3000 \
        --health-cmd="curl -f http://localhost:3000/health || exit 1" \
        --health-interval=30s \
        --health-timeout=10s \
        --health-retries=3 \
        $IMAGE_NAME:$VERSION

    # ç­‰å¾…å®¹å™¨å¯åŠ¨
    sleep 10

    # å¥åº·æ£€æŸ¥
    health_check $target_container $target_port

    # åˆ‡æ¢æµé‡
    update_nginx_config $target_env

    log "éƒ¨ç½²å®Œæˆ: $target_env"
    return 0
}

# å›æ»šæ“ä½œ
rollback() {
    local current_active=$(get_active_container)
    local rollback_target

    if [ "$current_active" = "blue" ]; then
        rollback_target="green"
    elif [ "$current_active" = "green" ]; then
        rollback_target="blue"
    else
        error "æ²¡æœ‰æ‰¾åˆ°å¯å›æ»šçš„å®¹å™¨"
    fi

    warn "å¼€å§‹å›æ»šåˆ°: $rollback_target"
    update_nginx_config $rollback_target
    log "å›æ»šå®Œæˆ"
}

# æ¸…ç†æ—§å®¹å™¨
cleanup() {
    local active_container=$(get_active_container)
    local cleanup_container

    if [ "$active_container" = "blue" ]; then
        cleanup_container=$GREEN_CONTAINER
    else
        cleanup_container=$BLUE_CONTAINER
    fi

    if docker ps | grep -q $cleanup_container; then
        log "æ¸…ç†éæ´»è·ƒå®¹å™¨: $cleanup_container"
        docker stop $cleanup_container
        docker rm $cleanup_container
    fi
}

# ä¸»å‡½æ•°
main() {
    case "${1:-deploy}" in
        "deploy")
            log "å¼€å§‹è“ç»¿éƒ¨ç½²: ç‰ˆæœ¬ $VERSION"
            deploy_new_version
            log "éƒ¨ç½²æˆåŠŸå®Œæˆ"
            ;;
        "rollback")
            rollback
            ;;
        "cleanup")
            cleanup
            ;;
        "status")
            local active=$(get_active_container)
            log "å½“å‰æ´»è·ƒç¯å¢ƒ: $active"
            ;;
        *)
            echo "ç”¨æ³•: $0 {deploy|rollback|cleanup|status} [version]"
            exit 1
            ;;
    esac
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
```

### 2. Docker Compose ç”Ÿäº§ç¯å¢ƒé…ç½®

```yaml
# docker-compose.prod.yml
version: "3.8"

services:
  # Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: nginx-proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/logs:/var/log/nginx
      - nginx_cache:/var/cache/nginx
    depends_on:
      - app-blue
      - app-green
    networks:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "com.centurylinklabs.watchtower.enable=false"

  # åº”ç”¨è“è‰²ç¯å¢ƒ
  app-blue:
    build:
      context: .
      dockerfile: Dockerfile.prod
    container_name: app-blue
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=3000
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET=${JWT_SECRET}
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    networks:
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # åº”ç”¨ç»¿è‰²ç¯å¢ƒ
  app-green:
    build:
      context: .
      dockerfile: Dockerfile.prod
    container_name: app-green
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=3000
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET=${JWT_SECRET}
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    networks:
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # æ•°æ®åº“
  database:
    image: postgres:15-alpine
    container_name: postgres-db
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
      - ./database/backups:/backups
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis ç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: redis-cache
    restart: unless-stopped
    command: >
      --requirepass ${REDIS_PASSWORD}
      --appendonly yes
      --appendfsync everysec
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    networks:
      - backend
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ç›‘æ§ - Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--storage.tsdb.retention.time=200h"
      - "--web.enable-lifecycle"
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    networks:
      - monitoring
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:9090/-/healthy",
        ]
      interval: 30s
      timeout: 10s
      retries: 3

  # ç›‘æ§ - Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    networks:
      - monitoring
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # æ—¥å¿—æ”¶é›† - Filebeat
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.5.0
    container_name: filebeat
    restart: unless-stopped
    user: root
    volumes:
      - ./monitoring/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ./logs:/var/log/app
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - monitoring
    depends_on:
      - app-blue
      - app-green

  # è‡ªåŠ¨æ›´æ–°æœåŠ¡
  watchtower:
    image: containrrr/watchtower
    container_name: watchtower
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_POLL_INTERVAL=3600
      - WATCHTOWER_INCLUDE_STOPPED=true
      - WATCHTOWER_LABEL_ENABLE=true
    networks:
      - backend

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
  monitoring:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  nginx_cache:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—ç®¡ç†

### 1. Prometheus é…ç½®

```yaml
# monitoring/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093

scrape_configs:
  # Prometheus è‡ªç›‘æ§
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]

  # Node Exporter
  - job_name: "node"
    static_configs:
      - targets: ["node-exporter:9100"]

  # Nginx ç›‘æ§
  - job_name: "nginx"
    static_configs:
      - targets: ["nginx:9113"]
    metrics_path: /metrics

  # åº”ç”¨ç›‘æ§
  - job_name: "app-blue"
    static_configs:
      - targets: ["app-blue:3000"]
    metrics_path: /metrics
    scrape_interval: 10s

  - job_name: "app-green"
    static_configs:
      - targets: ["app-green:3000"]
    metrics_path: /metrics
    scrape_interval: 10s

  # Docker ç›‘æ§
  - job_name: "docker"
    static_configs:
      - targets: ["cadvisor:8080"]

  # æ•°æ®åº“ç›‘æ§
  - job_name: "postgres"
    static_configs:
      - targets: ["postgres-exporter:9187"]

  - job_name: "redis"
    static_configs:
      - targets: ["redis-exporter:9121"]
```

### 2. å‘Šè­¦è§„åˆ™é…ç½®

```yaml
# monitoring/prometheus/alert_rules.yml
groups:
  - name: application_alerts
    rules:
      # åº”ç”¨å¥åº·æ£€æŸ¥
      - alert: ApplicationDown
        expr: up{job=~"app-.*"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Application {{ $labels.job }} is down"
          description: "Application {{ $labels.job }} has been down for more than 30 seconds"

      # é«˜é”™è¯¯ç‡
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

      # é«˜å“åº”æ—¶é—´
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }} seconds"

  - name: infrastructure_alerts
    rules:
      # é«˜ CPU ä½¿ç”¨ç‡
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

      # é«˜å†…å­˜ä½¿ç”¨ç‡
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

      # ç£ç›˜ç©ºé—´ä¸è¶³
      - alert: LowDiskSpace
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low disk space"
          description: "Disk space is {{ $value }}% on {{ $labels.instance }}"

  - name: nginx_alerts
    rules:
      # Nginx é«˜é”™è¯¯ç‡
      - alert: NginxHighErrorRate
        expr: rate(nginx_http_requests_total{status=~"4..|5.."}[5m]) / rate(nginx_http_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Nginx high error rate"
          description: "Nginx error rate is {{ $value | humanizePercentage }}"

      # Nginx è¿æ¥æ•°è¿‡é«˜
      - alert: NginxHighConnections
        expr: nginx_connections_active > 1000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Nginx high connection count"
          description: "Nginx has {{ $value }} active connections"
```

### 3. æ—¥å¿—é…ç½®

```yaml
# monitoring/filebeat/filebeat.yml
filebeat.inputs:
  # åº”ç”¨æ—¥å¿—
  - type: log
    enabled: true
    paths:
      - /var/log/app/*.log
    fields:
      service: application
      environment: production
    fields_under_root: true
    multiline.pattern: '^\d{4}-\d{2}-\d{2}'
    multiline.negate: true
    multiline.match: after

  # Nginx è®¿é—®æ—¥å¿—
  - type: log
    enabled: true
    paths:
      - /var/log/nginx/access.log
    fields:
      service: nginx
      log_type: access
    fields_under_root: true

  # Nginx é”™è¯¯æ—¥å¿—
  - type: log
    enabled: true
    paths:
      - /var/log/nginx/error.log
    fields:
      service: nginx
      log_type: error
    fields_under_root: true

  # Docker å®¹å™¨æ—¥å¿—
  - type: container
    paths:
      - "/var/lib/docker/containers/*/*.log"
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"

# è¾“å‡ºé…ç½®
output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "filebeat-%{+yyyy.MM.dd}"
  template.settings:
    index.number_of_shards: 1
    index.number_of_replicas: 0

# å¤„ç†å™¨
processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_cloud_metadata: ~
  - add_docker_metadata: ~

# æ—¥å¿—çº§åˆ«
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

## ğŸ”§ è¿ç»´è„šæœ¬å’Œå·¥å…·

### 1. éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy.sh - å®Œæ•´éƒ¨ç½²è„šæœ¬

set -euo pipefail

# é…ç½®å˜é‡
PROJECT_NAME="myapp"
DOCKER_REGISTRY="registry.example.com"
ENVIRONMENT=${1:-staging}
VERSION=${2:-latest}
COMPOSE_FILE="docker-compose.${ENVIRONMENT}.yml"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# æ—¥å¿—å‡½æ•°
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

error() {
    echo -e "${RED}[ERROR] $1${NC}"
    exit 1
}

warn() {
    echo -e "${YELLOW}[WARN] $1${NC}"
}

info() {
    echo -e "${BLUE}[INFO] $1${NC}"
}

# æ£€æŸ¥ä¾èµ–
check_dependencies() {
    local deps=("docker" "docker-compose" "curl" "jq")

    for dep in "${deps[@]}"; do
        if ! command -v "$dep" &> /dev/null; then
            error "$dep æœªå®‰è£…"
        fi
    done

    log "ä¾èµ–æ£€æŸ¥é€šè¿‡"
}

# æ£€æŸ¥ç¯å¢ƒå˜é‡
check_environment() {
    local required_vars=(
        "DATABASE_URL"
        "REDIS_URL"
        "JWT_SECRET"
    )

    for var in "${required_vars[@]}"; do
        if [[ -z "${!var:-}" ]]; then
            error "ç¯å¢ƒå˜é‡ $var æœªè®¾ç½®"
        fi
    done

    log "ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡"
}

# æ„å»ºé•œåƒ
build_images() {
    log "å¼€å§‹æ„å»ºé•œåƒ..."

    # æ„å»ºåº”ç”¨é•œåƒ
    docker build \
        --build-arg VERSION="$VERSION" \
        --build-arg BUILD_DATE="$(date -u +'%Y-%m-%dT%H:%M:%SZ')" \
        --build-arg VCS_REF="$(git rev-parse --short HEAD)" \
        -t "$DOCKER_REGISTRY/$PROJECT_NAME:$VERSION" \
        -t "$DOCKER_REGISTRY/$PROJECT_NAME:latest" \
        .

    # æ¨é€é•œåƒï¼ˆå¦‚æœæ˜¯ç”Ÿäº§ç¯å¢ƒï¼‰
    if [[ "$ENVIRONMENT" == "production" ]]; then
        log "æ¨é€é•œåƒåˆ°ä»“åº“..."
        docker push "$DOCKER_REGISTRY/$PROJECT_NAME:$VERSION"
        docker push "$DOCKER_REGISTRY/$PROJECT_NAME:latest"
    fi

    log "é•œåƒæ„å»ºå®Œæˆ"
}

# æ•°æ®åº“è¿ç§»
run_migrations() {
    log "è¿è¡Œæ•°æ®åº“è¿ç§»..."

    docker-compose -f "$COMPOSE_FILE" run --rm \
        -e DATABASE_URL="$DATABASE_URL" \
        app npm run migrate

    log "æ•°æ®åº“è¿ç§»å®Œæˆ"
}

# å¥åº·æ£€æŸ¥
health_check() {
    local service=$1
    local port=$2
    local endpoint=${3:-/health}
    local max_attempts=30
    local attempt=1

    log "å¥åº·æ£€æŸ¥: $service"

    while [[ $attempt -le $max_attempts ]]; do
        if curl -f -s "http://localhost:$port$endpoint" > /dev/null; then
            log "$service å¥åº·æ£€æŸ¥é€šè¿‡"
            return 0
        fi

        info "å¥åº·æ£€æŸ¥ $attempt/$max_attempts å¤±è´¥ï¼Œç­‰å¾… 10 ç§’..."
        sleep 10
        ((attempt++))
    done

    error "$service å¥åº·æ£€æŸ¥å¤±è´¥"
}

# éƒ¨ç½²æœåŠ¡
deploy_services() {
    log "å¼€å§‹éƒ¨ç½²æœåŠ¡..."

    # åœæ­¢æ—§æœåŠ¡
    docker-compose -f "$COMPOSE_FILE" down --remove-orphans

    # æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ
    docker image prune -f

    # å¯åŠ¨æ–°æœåŠ¡
    docker-compose -f "$COMPOSE_FILE" up -d

    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    sleep 30

    # å¥åº·æ£€æŸ¥
    health_check "nginx" "80"
    health_check "app" "3000"

    log "æœåŠ¡éƒ¨ç½²å®Œæˆ"
}

# å¤‡ä»½æ•°æ®
backup_data() {
    if [[ "$ENVIRONMENT" == "production" ]]; then
        log "å¼€å§‹æ•°æ®å¤‡ä»½..."

        local backup_file="backup_$(date +%Y%m%d_%H%M%S).sql"

        docker-compose -f "$COMPOSE_FILE" exec -T database \
            pg_dump -U "$DB_USER" "$DB_NAME" > "./backups/$backup_file"

        # å‹ç¼©å¤‡ä»½æ–‡ä»¶
        gzip "./backups/$backup_file"

        log "æ•°æ®å¤‡ä»½å®Œæˆ: $backup_file.gz"
    fi
}

# å‘é€é€šçŸ¥
send_notification() {
    local status=$1
    local message="éƒ¨ç½² $ENVIRONMENT ç¯å¢ƒ - çŠ¶æ€: $status"

    if [[ -n "${SLACK_WEBHOOK:-}" ]]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"$message\"}" \
            "$SLACK_WEBHOOK"
    fi

    if [[ -n "${EMAIL_RECIPIENT:-}" ]]; then
        echo "$message" | mail -s "éƒ¨ç½²é€šçŸ¥" "$EMAIL_RECIPIENT"
    fi
}

# å›æ»šå‡½æ•°
rollback() {
    warn "å¼€å§‹å›æ»šæ“ä½œ..."

    # è·å–ä¸Šä¸€ä¸ªç‰ˆæœ¬
    local previous_version
    previous_version=$(docker images --format "table {{.Repository}}:{{.Tag}}" | \
        grep "$DOCKER_REGISTRY/$PROJECT_NAME" | \
        grep -v latest | \
        head -2 | tail -1 | cut -d: -f2)

    if [[ -z "$previous_version" ]]; then
        error "æ²¡æœ‰æ‰¾åˆ°å¯å›æ»šçš„ç‰ˆæœ¬"
    fi

    # ä½¿ç”¨ä¸Šä¸€ä¸ªç‰ˆæœ¬é‡æ–°éƒ¨ç½²
    VERSION="$previous_version" deploy_services

    log "å›æ»šå®Œæˆï¼Œå½“å‰ç‰ˆæœ¬: $previous_version"
}

# æ¸…ç†å‡½æ•°
cleanup() {
    log "å¼€å§‹æ¸…ç†..."

    # æ¸…ç†åœæ­¢çš„å®¹å™¨
    docker container prune -f

    # æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ
    docker image prune -f

    # æ¸…ç†æœªä½¿ç”¨çš„ç½‘ç»œ
    docker network prune -f

    # æ¸…ç†æœªä½¿ç”¨çš„å·
    docker volume prune -f

    log "æ¸…ç†å®Œæˆ"
}

# æ˜¾ç¤ºçŠ¶æ€
show_status() {
    log "æœåŠ¡çŠ¶æ€:"
    docker-compose -f "$COMPOSE_FILE" ps

    log "èµ„æºä½¿ç”¨æƒ…å†µ:"
    docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}\t{{.BlockIO}}"
}

# ä¸»å‡½æ•°
main() {
    case "${1:-deploy}" in
        "deploy")
            log "å¼€å§‹éƒ¨ç½² $ENVIRONMENT ç¯å¢ƒï¼Œç‰ˆæœ¬: $VERSION"
            check_dependencies
            check_environment
            backup_data
            build_images
            run_migrations
            deploy_services
            send_notification "æˆåŠŸ"
            log "éƒ¨ç½²å®Œæˆ"
            ;;
        "rollback")
            rollback
            send_notification "å›æ»šå®Œæˆ"
            ;;
        "cleanup")
            cleanup
            ;;
        "status")
            show_status
            ;;
        "health")
            health_check "nginx" "80"
            health_check "app" "3000"
            ;;
        *)
            echo "ç”¨æ³•: $0 {deploy|rollback|cleanup|status|health} [environment] [version]"
            echo "  deploy   - éƒ¨ç½²åº”ç”¨"
            echo "  rollback - å›æ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬"
            echo "  cleanup  - æ¸…ç†æœªä½¿ç”¨çš„èµ„æº"
            echo "  status   - æ˜¾ç¤ºæœåŠ¡çŠ¶æ€"
            echo "  health   - è¿è¡Œå¥åº·æ£€æŸ¥"
            exit 1
            ;;
    esac
}

# é”™è¯¯å¤„ç†
trap 'error "éƒ¨ç½²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¡Œå·: $LINENO"' ERR
trap 'log "éƒ¨ç½²è„šæœ¬é€€å‡º"' EXIT

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
```

### 2. ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# monitor.sh - ç³»ç»Ÿç›‘æ§è„šæœ¬

set -euo pipefail

# é…ç½®
COMPOSE_FILE="docker-compose.prod.yml"
LOG_FILE="/var/log/monitor.log"
ALERT_THRESHOLD_CPU=80
ALERT_THRESHOLD_MEMORY=85
ALERT_THRESHOLD_DISK=90

# æ—¥å¿—å‡½æ•°
log() {
    echo "$(date +'%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

# æ£€æŸ¥å®¹å™¨çŠ¶æ€
check_containers() {
    log "æ£€æŸ¥å®¹å™¨çŠ¶æ€..."

    local unhealthy_containers=()

    while IFS= read -r container; do
        local status
        status=$(docker inspect --format='{{.State.Health.Status}}' "$container" 2>/dev/null || echo "no-health-check")

        if [[ "$status" == "unhealthy" ]]; then
            unhealthy_containers+=("$container")
        fi
    done < <(docker-compose -f "$COMPOSE_FILE" ps -q)

    if [[ ${#unhealthy_containers[@]} -gt 0 ]]; then
        log "å‘ç°ä¸å¥åº·å®¹å™¨: ${unhealthy_containers[*]}"
        send_alert "å®¹å™¨å¥åº·æ£€æŸ¥å¤±è´¥" "ä¸å¥åº·å®¹å™¨: ${unhealthy_containers[*]}"
        return 1
    fi

    log "æ‰€æœ‰å®¹å™¨å¥åº·çŠ¶æ€æ­£å¸¸"
    return 0
}

# æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ
check_resources() {
    log "æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ..."

    # CPU ä½¿ç”¨ç‡
    local cpu_usage
    cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')

    if (( $(echo "$cpu_usage > $ALERT_THRESHOLD_CPU" | bc -l) )); then
        log "CPU ä½¿ç”¨ç‡è¿‡é«˜: ${cpu_usage}%"
        send_alert "CPU ä½¿ç”¨ç‡å‘Šè­¦" "å½“å‰ CPU ä½¿ç”¨ç‡: ${cpu_usage}%"
    fi

    # å†…å­˜ä½¿ç”¨ç‡
    local memory_usage
    memory_usage=$(free | grep Mem | awk '{printf "%.1f", $3/$2 * 100.0}')

    if (( $(echo "$memory_usage > $ALERT_THRESHOLD_MEMORY" | bc -l) )); then
        log "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: ${memory_usage}%"
        send_alert "å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦" "å½“å‰å†…å­˜ä½¿ç”¨ç‡: ${memory_usage}%"
    fi

    # ç£ç›˜ä½¿ç”¨ç‡
    while IFS= read -r line; do
        local usage
        usage=$(echo "$line" | awk '{print $5}' | sed 's/%//')
        local mount
        mount=$(echo "$line" | awk '{print $6}')

        if [[ "$usage" -gt "$ALERT_THRESHOLD_DISK" ]]; then
            log "ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: $mount ${usage}%"
            send_alert "ç£ç›˜ä½¿ç”¨ç‡å‘Šè­¦" "æŒ‚è½½ç‚¹ $mount ä½¿ç”¨ç‡: ${usage}%"
        fi
    done < <(df -h | grep -E '^/dev/')

    log "èµ„æºæ£€æŸ¥å®Œæˆ"
}

# æ£€æŸ¥æœåŠ¡å“åº”
check_service_response() {
    log "æ£€æŸ¥æœåŠ¡å“åº”..."

    local endpoints=(
        "http://localhost/health"
        "http://localhost/api/health"
    )

    for endpoint in "${endpoints[@]}"; do
        local response_time
        response_time=$(curl -o /dev/null -s -w "%{time_total}" "$endpoint" || echo "0")

        if (( $(echo "$response_time == 0" | bc -l) )); then
            log "æœåŠ¡ä¸å¯è¾¾: $endpoint"
            send_alert "æœåŠ¡ä¸å¯è¾¾" "ç«¯ç‚¹ $endpoint æ— å“åº”"
        elif (( $(echo "$response_time > 5" | bc -l) )); then
            log "æœåŠ¡å“åº”ç¼“æ…¢: $endpoint (${response_time}s)"
            send_alert "æœåŠ¡å“åº”ç¼“æ…¢" "ç«¯ç‚¹ $endpoint å“åº”æ—¶é—´: ${response_time}s"
        fi
    done

    log "æœåŠ¡å“åº”æ£€æŸ¥å®Œæˆ"
}

# æ£€æŸ¥æ—¥å¿—é”™è¯¯
check_logs() {
    log "æ£€æŸ¥åº”ç”¨æ—¥å¿—..."

    local error_count
    error_count=$(docker-compose -f "$COMPOSE_FILE" logs --since="5m" 2>&1 | grep -i "error\|exception\|fatal" | wc -l)

    if [[ "$error_count" -gt 10 ]]; then
        log "å‘ç°å¤§é‡é”™è¯¯æ—¥å¿—: $error_count æ¡"
        send_alert "åº”ç”¨é”™è¯¯å‘Šè­¦" "æœ€è¿‘ 5 åˆ†é’Ÿå†…å‘ç° $error_count æ¡é”™è¯¯æ—¥å¿—"
    fi

    log "æ—¥å¿—æ£€æŸ¥å®Œæˆ"
}

# å‘é€å‘Šè­¦
send_alert() {
    local title=$1
    local message=$2

    log "å‘é€å‘Šè­¦: $title - $message"

    # Slack é€šçŸ¥
    if [[ -n "${SLACK_WEBHOOK:-}" ]]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"ğŸš¨ $title\\n$message\"}" \
            "$SLACK_WEBHOOK"
    fi

    # é‚®ä»¶é€šçŸ¥
    if [[ -n "${EMAIL_RECIPIENT:-}" ]]; then
        echo "$message" | mail -s "$title" "$EMAIL_RECIPIENT"
    fi

    # ä¼ä¸šå¾®ä¿¡é€šçŸ¥
    if [[ -n "${WECHAT_WEBHOOK:-}" ]]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"msgtype\":\"text\",\"text\":{\"content\":\"$title: $message\"}}" \
            "$WECHAT_WEBHOOK"
    fi
}

# ç”ŸæˆæŠ¥å‘Š
generate_report() {
    log "ç”Ÿæˆç›‘æ§æŠ¥å‘Š..."

    local report_file="/tmp/monitor_report_$(date +%Y%m%d_%H%M%S).txt"

    {
        echo "=== ç³»ç»Ÿç›‘æ§æŠ¥å‘Š ==="
        echo "æ—¶é—´: $(date)"
        echo ""

        echo "=== å®¹å™¨çŠ¶æ€ ==="
        docker-compose -f "$COMPOSE_FILE" ps
        echo ""

        echo "=== èµ„æºä½¿ç”¨æƒ…å†µ ==="
        echo "CPU: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}')"
        echo "å†…å­˜: $(free -h | grep Mem)"
        echo "ç£ç›˜: $(df -h | grep -E '^/dev/')"
        echo ""

        echo "=== ç½‘ç»œè¿æ¥ ==="
        netstat -tuln | head -20
        echo ""

        echo "=== æœ€è¿‘é”™è¯¯æ—¥å¿— ==="
        docker-compose -f "$COMPOSE_FILE" logs --since="1h" 2>&1 | grep -i "error\|exception\|fatal" | tail -10

    } > "$report_file"

    log "ç›‘æ§æŠ¥å‘Šç”Ÿæˆ: $report_file"

    # å¦‚æœæ˜¯æ¯æ—¥æŠ¥å‘Šï¼Œå‘é€é‚®ä»¶
    if [[ "${1:-}" == "daily" ]]; then
        if [[ -n "${EMAIL_RECIPIENT:-}" ]]; then
            mail -s "æ¯æ—¥ç›‘æ§æŠ¥å‘Š" "$EMAIL_RECIPIENT" < "$report_file"
        fi
    fi
}

# è‡ªåŠ¨ä¿®å¤
auto_fix() {
    log "å¼€å§‹è‡ªåŠ¨ä¿®å¤..."

    # é‡å¯ä¸å¥åº·çš„å®¹å™¨
    local unhealthy_containers
    unhealthy_containers=$(docker ps --filter "health=unhealthy" --format "{{.Names}}")

    if [[ -n "$unhealthy_containers" ]]; then
        log "é‡å¯ä¸å¥åº·å®¹å™¨: $unhealthy_containers"
        echo "$unhealthy_containers" | xargs -r docker restart

        # ç­‰å¾…å®¹å™¨é‡å¯
        sleep 30

        # å†æ¬¡æ£€æŸ¥
        if ! check_containers; then
            send_alert "è‡ªåŠ¨ä¿®å¤å¤±è´¥" "å®¹å™¨é‡å¯åä»ç„¶ä¸å¥åº·"
        else
            log "å®¹å™¨è‡ªåŠ¨ä¿®å¤æˆåŠŸ"
        fi
    fi

    # æ¸…ç†ç£ç›˜ç©ºé—´
    if (( $(df / | tail -1 | awk '{print $5}' | sed 's/%//') > 85 )); then
        log "æ¸…ç†ç£ç›˜ç©ºé—´..."
        docker system prune -f
        docker volume prune -f

        # æ¸…ç†æ—¥å¿—æ–‡ä»¶
        find /var/log -name "*.log" -type f -size +100M -exec truncate -s 50M {} \;

        log "ç£ç›˜æ¸…ç†å®Œæˆ"
    fi
}

# ä¸»å‡½æ•°
main() {
    case "${1:-check}" in
        "check")
            log "å¼€å§‹ç³»ç»Ÿæ£€æŸ¥..."
            check_containers
            check_resources
            check_service_response
            check_logs
            log "ç³»ç»Ÿæ£€æŸ¥å®Œæˆ"
            ;;
        "fix")
            auto_fix
            ;;
        "report")
            generate_report "${2:-}"
            ;;
        "alert-test")
            send_alert "æµ‹è¯•å‘Šè­¦" "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å‘Šè­¦æ¶ˆæ¯"
            ;;
        *)
            echo "ç”¨æ³•: $0 {check|fix|report|alert-test}"
            echo "  check      - è¿è¡Œç³»ç»Ÿæ£€æŸ¥"
            echo "  fix        - è‡ªåŠ¨ä¿®å¤é—®é¢˜"
            echo "  report     - ç”Ÿæˆç›‘æ§æŠ¥å‘Š"
            echo "  alert-test - æµ‹è¯•å‘Šè­¦åŠŸèƒ½"
            exit 1
            ;;
    esac
}

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p "$(dirname "$LOG_FILE")"

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
```

## ğŸ”’ å®‰å…¨é…ç½®

### 1. Docker å®‰å…¨é…ç½®

```dockerfile
# Dockerfile.security - å®‰å…¨åŠ å›ºç‰ˆæœ¬
FROM node:18-alpine AS base

# å®‰å…¨æ›´æ–°
RUN apk update && apk upgrade && apk add --no-cache dumb-init

# åˆ›å»ºéç‰¹æƒç”¨æˆ·
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001 -G nodejs

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY package*.json ./

# å®‰è£…ä¾èµ–
RUN npm ci --only=production && \
    npm cache clean --force && \
    rm -rf /tmp/*

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY --chown=nodejs:nodejs . .

# è®¾ç½®æ­£ç¡®çš„æƒé™
RUN chown -R nodejs:nodejs /app && \
    chmod -R 755 /app

# åˆ‡æ¢åˆ°éç‰¹æƒç”¨æˆ·
USER nodejs

# æš´éœ²ç«¯å£
EXPOSE 3000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD node healthcheck.js

# å®‰å…¨å¯åŠ¨
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "index.js"]
```

### 2. Nginx å®‰å…¨é…ç½®

```nginx
# security.conf - Nginx å®‰å…¨é…ç½®
# éšè—ç‰ˆæœ¬ä¿¡æ¯
server_tokens off;

# å®‰å…¨å¤´
add_header X-Frame-Options "SAMEORIGIN" always;
add_header X-XSS-Protection "1; mode=block" always;
add_header X-Content-Type-Options "nosniff" always;
add_header Referrer-Policy "strict-origin-when-cross-origin" always;
add_header Permissions-Policy "geolocation=(), microphone=(), camera=()" always;

# CSP ç­–ç•¥
add_header Content-Security-Policy "
    default-src 'self';
    script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdn.jsdelivr.net;
    style-src 'self' 'unsafe-inline' https://fonts.googleapis.com;
    img-src 'self' data: https:;
    font-src 'self' https://fonts.gstatic.com;
    connect-src 'self' https://api.example.com;
    frame-ancestors 'none';
    base-uri 'self';
    form-action 'self';
" always;

# HSTS
add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;

# é™åˆ¶è¯·æ±‚æ–¹æ³•
if ($request_method !~ ^(GET|HEAD|POST|PUT|DELETE|OPTIONS)$) {
    return 405;
}

# é™åˆ¶æ–‡ä»¶ä¸Šä¼ å¤§å°
client_max_body_size 10M;

# ç¦æ­¢è®¿é—®éšè—æ–‡ä»¶
location ~ /\. {
    deny all;
    access_log off;
    log_not_found off;
}

# ç¦æ­¢è®¿é—®å¤‡ä»½æ–‡ä»¶
location ~* \.(bak|backup|old|orig|original|tmp|temp|~)$ {
    deny all;
    access_log off;
    log_not_found off;
}

# é™åˆ¶ç‰¹å®š User-Agent
if ($http_user_agent ~* (bot|crawler|scanner|spider)) {
    return 403;
}

# IP ç™½åå•ï¼ˆç®¡ç†æ¥å£ï¼‰
location /admin {
    allow 192.168.1.0/24;
    allow 10.0.0.0/8;
    deny all;

    proxy_pass http://backend;
    include /etc/nginx/proxy_headers.conf;
}

# é˜²æ­¢ SQL æ³¨å…¥å’Œ XSS
location / {
    # æ£€æŸ¥æ¶æ„å‚æ•°
    if ($args ~* "(\<|%3C).*script.*(\>|%3E)") {
        return 403;
    }
    if ($args ~* "UNION.*SELECT") {
        return 403;
    }
    if ($args ~* "INSERT.*INTO") {
        return 403;
    }
    if ($args ~* "DELETE.*FROM") {
        return 403;
    }
    if ($args ~* "DROP.*TABLE") {
        return 403;
    }

    try_files $uri $uri/ /index.html;
}
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. Docker é•œåƒä¼˜åŒ–

```dockerfile
# Dockerfile.optimized - ä¼˜åŒ–ç‰ˆæœ¬
# ä½¿ç”¨å¤šé˜¶æ®µæ„å»º
FROM node:18-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…æ„å»ºä¾èµ–
RUN apk add --no-cache python3 make g++

# å¤åˆ¶ package æ–‡ä»¶å¹¶å®‰è£…ä¾èµ–
COPY package*.json ./
RUN npm ci --include=dev

# å¤åˆ¶æºä»£ç å¹¶æ„å»º
COPY . .
RUN npm run build && npm prune --production

# ç”Ÿäº§é•œåƒ
FROM node:18-alpine AS production

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apk add --no-cache dumb-init curl && \
    addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001 -G nodejs

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶æ–‡ä»¶
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/package*.json ./

# åˆ‡æ¢ç”¨æˆ·
USER nodejs

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:3000/health || exit 1

# å¯åŠ¨åº”ç”¨
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/index.js"]
```

### 2. Nginx æ€§èƒ½ä¼˜åŒ–

```nginx
# performance.conf - æ€§èƒ½ä¼˜åŒ–é…ç½®
# å·¥ä½œè¿›ç¨‹ä¼˜åŒ–
worker_processes auto;
worker_cpu_affinity auto;
worker_rlimit_nofile 65535;

events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
    accept_mutex off;
}

http {
    # åŸºç¡€ä¼˜åŒ–
    sendfile on;
    sendfile_max_chunk 1m;
    tcp_nopush on;
    tcp_nodelay on;

    # è¿æ¥ä¼˜åŒ–
    keepalive_timeout 65;
    keepalive_requests 1000;

    # ç¼“å†²åŒºä¼˜åŒ–
    client_body_buffer_size 256k;
    client_header_buffer_size 64k;
    large_client_header_buffers 4 64k;
    output_buffers 2 32k;
    postpone_output 1460;

    # å‹ç¼©ä¼˜åŒ–
    gzip on;
    gzip_vary on;
    gzip_min_length 1000;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # ç¼“å­˜ä¼˜åŒ–
    open_file_cache max=100000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;

    # ä»£ç†ç¼“å­˜
    proxy_cache_path /var/cache/nginx/proxy
                     levels=1:2
                     keys_zone=my_cache:10m
                     max_size=10g
                     inactive=60m
                     use_temp_path=off;

    # ä¸Šæ¸¸è¿æ¥æ± 
    upstream backend {
        least_conn;
        server backend:3000 max_fails=3 fail_timeout=30s;
        keepalive 32;
        keepalive_requests 100;
        keepalive_timeout 60s;
    }

    server {
        listen 443 ssl http2;
        server_name example.com;

        # SSL ä¼šè¯ç¼“å­˜
        ssl_session_cache shared:SSL:50m;
        ssl_session_timeout 1d;
        ssl_session_tickets off;

        # é™æ€æ–‡ä»¶ç¼“å­˜
        location ~* \.(css|js|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            add_header Vary Accept-Encoding;

            # å¯ç”¨ gzip é™æ€æ–‡ä»¶
            gzip_static on;

            # å…³é—­è®¿é—®æ—¥å¿—
            access_log off;

            # é¢„å‹ç¼©æ–‡ä»¶æ”¯æŒ
            location ~* \.css$ {
                add_header Content-Type text/css;
            }
            location ~* \.js$ {
                add_header Content-Type application/javascript;
            }
        }

        # API ç¼“å­˜
        location /api/public/ {
            proxy_pass http://backend;
            proxy_cache my_cache;
            proxy_cache_valid 200 302 10m;
            proxy_cache_valid 404 1m;
            proxy_cache_key "$scheme$request_method$host$request_uri";
            proxy_cache_bypass $arg_nocache;

            add_header X-Cache-Status $upstream_cache_status;

            include /etc/nginx/proxy_headers.conf;
        }

        # ä¸»è¦ä»£ç†é…ç½®
        location / {
            proxy_pass http://backend;
            proxy_buffering on;
            proxy_buffer_size 128k;
            proxy_buffers 4 256k;
            proxy_busy_buffers_size 256k;

            include /etc/nginx/proxy_headers.conf;
        }
    }
}
```

---

## ğŸ¯ æ€»ç»“

Docker + Nginx çš„ç»„åˆä¸ºç°ä»£ Web åº”ç”¨æä¾›äº†å¼ºå¤§è€Œçµæ´»çš„éƒ¨ç½²è§£å†³æ–¹æ¡ˆï¼š

### Docker ä¼˜åŠ¿ï¼š

- **ç¯å¢ƒä¸€è‡´æ€§**ï¼šå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒå®Œå…¨ä¸€è‡´
- **èµ„æºéš”ç¦»**ï¼šå®¹å™¨é—´äº’ä¸å¹²æ‰°ï¼Œæé«˜å®‰å…¨æ€§
- **å¼¹æ€§æ‰©å±•**ï¼šè½»æ¾å®ç°æ°´å¹³æ‰©å±•å’Œè´Ÿè½½å‡è¡¡
- **å¿«é€Ÿéƒ¨ç½²**ï¼šé•œåƒåŒ–éƒ¨ç½²ï¼Œå›æ»šä¾¿æ·

### Nginx ä¼˜åŠ¿ï¼š

- **é«˜æ€§èƒ½**ï¼šäº‹ä»¶é©±åŠ¨æ¶æ„ï¼Œé«˜å¹¶å‘å¤„ç†èƒ½åŠ›
- **åå‘ä»£ç†**ï¼šè´Ÿè½½å‡è¡¡ã€SSL ç»ˆæ­¢ã€ç¼“å­˜åŠ é€Ÿ
- **å®‰å…¨é˜²æŠ¤**ï¼šè®¿é—®æ§åˆ¶ã€é™æµã€å®‰å…¨å¤´è®¾ç½®
- **çµæ´»é…ç½®**ï¼šä¸°å¯Œçš„æ¨¡å—å’Œé…ç½®é€‰é¡¹

### æœ€ä½³å®è·µè¦ç‚¹ï¼š

1. **å®‰å…¨ç¬¬ä¸€**ï¼š

   - ä½¿ç”¨é root ç”¨æˆ·è¿è¡Œå®¹å™¨
   - å®šæœŸæ›´æ–°åŸºç¡€é•œåƒå’Œä¾èµ–
   - é…ç½®å®‰å…¨å¤´å’Œè®¿é—®æ§åˆ¶

2. **æ€§èƒ½ä¼˜åŒ–**ï¼š

   - å¤šé˜¶æ®µæ„å»ºå‡å°é•œåƒä½“ç§¯
   - å¯ç”¨å‹ç¼©å’Œç¼“å­˜
   - åˆç†é…ç½®è¿æ¥æ± å’Œç¼“å†²åŒº

3. **ç›‘æ§å‘Šè­¦**ï¼š

   - å¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨é‡å¯
   - èµ„æºç›‘æ§å’Œæ€§èƒ½æŒ‡æ ‡
   - æ—¥å¿—èšåˆå’Œé”™è¯¯å‘Šè­¦

4. **éƒ¨ç½²ç­–ç•¥**ï¼š
   - è“ç»¿éƒ¨ç½²é›¶åœæœºæ›´æ–°
   - è‡ªåŠ¨åŒ–éƒ¨ç½²å’Œå›æ»š
   - ç¯å¢ƒéš”ç¦»å’Œé…ç½®ç®¡ç†

è¿™å¥— Docker + Nginx è§£å†³æ–¹æ¡ˆèƒ½å¤Ÿæ»¡è¶³ä»å°å‹åº”ç”¨åˆ°å¤§å‹ä¼ä¸šçº§ç³»ç»Ÿçš„å„ç§éƒ¨ç½²éœ€æ±‚ï¼Œæä¾›é«˜å¯ç”¨ã€é«˜æ€§èƒ½ã€æ˜“ç»´æŠ¤çš„ç”Ÿäº§ç¯å¢ƒï¼

---

ğŸ¯ **ä¸‹ä¸€æ­¥**: æŒæ¡ Docker + Nginx åï¼Œå»ºè®®å­¦ä¹  Kubernetes å®¹å™¨ç¼–æ’å’ŒæœåŠ¡ç½‘æ ¼ Istio æ¥æ„å»ºæ›´å¤§è§„æ¨¡çš„äº‘åŸç”Ÿåº”ç”¨ï¼
